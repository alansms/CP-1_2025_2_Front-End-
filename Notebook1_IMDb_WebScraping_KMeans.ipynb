{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: IMDb Top 250 Movies - Web Scraping e Clusterização KMeans\n",
    "\n",
    "**Objetivo:** Aprimorar o código de web scraping para obter dados dos 250 filmes do IMDb e treinar modelo KMeans com k=5\n",
    "\n",
    "**Desenvolvido por:** [Nome dos integrantes do grupo]\n",
    "\n",
    "**Data:** 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação das Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n",
      "Python version: 2.3.0\n",
      "NumPy version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# Instalação das bibliotecas necessárias (execute apenas se necessário)\n",
    "# !pip install requests beautifulsoup4 pandas numpy matplotlib seaborn plotly wordcloud scikit-learn nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "\n",
    "# Configurações\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "print(f\"Python version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Web Scraping - IMDb Top 250 Movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Função de web scraping definida!\n"
     ]
    }
   ],
   "source": [
    "# Web Scraping baseado no notebook de referência que funciona\n",
    "def scrape_imdb_top250():\n",
    "    \"\"\"\n",
    "    Função para fazer web scraping dos top 250 filmes do IMDb\n",
    "    \"\"\"\n",
    "    # User agents para evitar bloqueios\n",
    "    userAgents = [\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/74.0.3729.157 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.1.1 Safari/605.1.15\"\n",
    "    ]\n",
    "    \n",
    "    url = 'https://www.imdb.com/chart/top/?ref_=nv_mv_250'\n",
    "    \n",
    "    try:\n",
    "        print(\"Fazendo requisição para IMDb...\")\n",
    "        response = requests.get(url, headers={\"User-agent\": userAgents[1]})\n",
    "        print(f\"Status da resposta: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Erro na requisição: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "        html = response.text\n",
    "        bs = BeautifulSoup(html)\n",
    "        \n",
    "        # Extrair títulos\n",
    "        print(\"Extraindo títulos...\")\n",
    "        titles = bs.find_all('h3', attrs={'class':'ipc-title__text'})\n",
    "        list_title_en = []\n",
    "        for x in titles:\n",
    "            if x.text != 'IMDb Charts' and x.text != 'Recently viewed':\n",
    "                tit = (x.text).split('.')[-1].strip()\n",
    "                list_title_en.append(tit)\n",
    "        \n",
    "        print(f\"Encontrados {len(list_title_en)} títulos\")\n",
    "        \n",
    "        # Extrair anos\n",
    "        print(\"Extraindo anos...\")\n",
    "        list_years = []\n",
    "        years = bs.find_all('div', attrs={'class':'sc-b189961a-7 btCcOY cli-title-metadata'})\n",
    "        for year in years:\n",
    "            list_years.append(year.text[:4])\n",
    "        \n",
    "        print(f\"Encontrados {len(list_years)} anos\")\n",
    "        \n",
    "        # Extrair ratings\n",
    "        print(\"Extraindo ratings...\")\n",
    "        list_rating = []\n",
    "        rating_span = bs.find_all('span', class_='ipc-rating-star--rating')\n",
    "        for x in rating_span:\n",
    "            list_rating.append(x.text)\n",
    "        \n",
    "        print(f\"Encontrados {len(list_rating)} ratings\")\n",
    "        \n",
    "        # Extrair links dos filmes\n",
    "        print(\"Extraindo links dos filmes...\")\n",
    "        list_links = []\n",
    "        for a in bs.find_all('a', href=True):\n",
    "            if '/title/' in a['href'] and 'https://www.imdb.com/'+a['href'] not in list_links:\n",
    "                list_links.append(('https://www.imdb.com/'+a['href'])[:-15])\n",
    "        \n",
    "        # Remove duplicates\n",
    "        list_links = list(dict.fromkeys(list_links))\n",
    "        list_links = list_links[1:]\n",
    "        \n",
    "        print(f\"Encontrados {len(list_links)} links únicos\")\n",
    "        \n",
    "        # Headers para requisições individuais\n",
    "        headers = {\n",
    "            'authority': 'www.imdb.com',\n",
    "            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',\n",
    "            'accept-language': 'en-US,en;q=0.9',\n",
    "            'cache-control': 'max-age=0',\n",
    "            'sec-ch-ua': '\"Chromium\";v=\"110\", \"Not A(Brand\";v=\"24\", \"Google Chrome\";v=\"110\"',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'sec-ch-ua-platform': '\"Windows\"',\n",
    "            'sec-fetch-dest': 'document',\n",
    "            'sec-fetch-mode': 'navigate',\n",
    "            'sec-fetch-site': 'none',\n",
    "            'sec-fetch-user': '?1',\n",
    "            'upgrade-insecure-requests': '1',\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36',\n",
    "        }\n",
    "        \n",
    "        # Extrair detalhes dos filmes\n",
    "        print(\"Extraindo detalhes dos filmes...\")\n",
    "        list_genre = []\n",
    "        list_title_pt = []\n",
    "        list_year = []\n",
    "        list_sinopse = []\n",
    "        \n",
    "        for i, link in enumerate(list_links[:250]):  # Limitar a 250 filmes\n",
    "            try:\n",
    "                time.sleep(0.5)  # Pausa para evitar bloqueios\n",
    "                response = requests.get(link, headers=headers)\n",
    "                html = response.content\n",
    "                soup = BeautifulSoup(html, \"html.parser\")\n",
    "                \n",
    "                # Gênero\n",
    "                try:\n",
    "                    genre_element = soup.find('span', {'class':'ipc-chip__text'})\n",
    "                    if genre_element:\n",
    "                        genre = genre_element.text\n",
    "                        list_genre.append(genre)\n",
    "                    else:\n",
    "                        list_genre.append('N/A')\n",
    "                except:\n",
    "                    list_genre.append('N/A')\n",
    "                \n",
    "                # Título PT e ano\n",
    "                try:\n",
    "                    title_element = soup.find('title')\n",
    "                    if title_element:\n",
    "                        title_text = title_element.text\n",
    "                        # Título PT\n",
    "                        title_pt = title_text[:-14].strip()\n",
    "                        list_title_pt.append(title_pt)\n",
    "                        # Ano\n",
    "                        year = title_text[-12:-8].strip()\n",
    "                        list_year.append(year)\n",
    "                    else:\n",
    "                        list_title_pt.append('N/A')\n",
    "                        list_year.append('N/A')\n",
    "                except:\n",
    "                    list_title_pt.append('N/A')\n",
    "                    list_year.append('N/A')\n",
    "                \n",
    "                # Sinopse\n",
    "                try:\n",
    "                    sinopse_element = soup.find('span', {\"data-testid\":\"plot-xl\"})\n",
    "                    if sinopse_element:\n",
    "                        sinopse = sinopse_element.text\n",
    "                        list_sinopse.append(sinopse)\n",
    "                    else:\n",
    "                        list_sinopse.append('N/A')\n",
    "                except:\n",
    "                    list_sinopse.append('N/A')\n",
    "                \n",
    "                print(f\"Processando filme {i+1}/250: {list_title_en[i] if i < len(list_title_en) else 'N/A'}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar filme {i+1}: {str(e)}\")\n",
    "                list_genre.append('N/A')\n",
    "                list_title_pt.append('N/A')\n",
    "                list_year.append('N/A')\n",
    "                list_sinopse.append('N/A')\n",
    "                continue\n",
    "        \n",
    "        # Criar DataFrame\n",
    "        print(\"Criando DataFrame...\")\n",
    "        df = pd.DataFrame({\n",
    "            'title_pt': list_title_pt,\n",
    "            'title_en': list_title_en,\n",
    "            'year': list_year,\n",
    "            'rating': list_rating,\n",
    "            'genre': list_genre,\n",
    "            'sinopse': list_sinopse\n",
    "        })\n",
    "        \n",
    "        print(f\"DataFrame criado com shape: {df.shape}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro no web scraping: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"Função de web scraping definida!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando web scraping dos top 250 filmes do IMDb...\n",
      "Este processo pode levar alguns minutos...\n",
      "Fazendo requisição para IMDb...\n",
      "Status da resposta: 200\n",
      "Extraindo títulos...\n",
      "Encontrados 25 títulos\n",
      "Extraindo anos...\n",
      "Encontrados 0 anos\n",
      "Extraindo ratings...\n",
      "Encontrados 25 ratings\n",
      "Extraindo links dos filmes...\n",
      "Encontrados 25 links únicos\n",
      "Extraindo detalhes dos filmes...\n",
      "Processando filme 1/250: Um Sonho de Liberdade\n",
      "Processando filme 2/250: O Poderoso Chefão\n",
      "Processando filme 3/250: Batman: O Cavaleiro das Trevas\n",
      "Processando filme 4/250: O Poderoso Chefão: Parte II\n",
      "Processando filme 5/250: 12 Homens e uma Sentença\n",
      "Processando filme 6/250: O Senhor dos Anéis: O Retorno do Rei\n",
      "Processando filme 7/250: A Lista de Schindler\n",
      "Processando filme 8/250: O Senhor dos Anéis: A Sociedade do Anel\n",
      "Processando filme 9/250: Pulp Fiction: Tempo de Violência\n",
      "Processando filme 10/250: Três Homens em Conflito\n",
      "Processando filme 11/250: Forrest Gump: O Contador de Histórias\n",
      "Processando filme 12/250: O Senhor dos Anéis: As Duas Torres\n",
      "Processando filme 13/250: Clube da Luta\n",
      "Processando filme 14/250: A Origem\n",
      "Processando filme 15/250: Star Wars: Episódio V - O Império Contra-Ataca\n",
      "Processando filme 16/250: Matrix\n",
      "Processando filme 17/250: Os Bons Companheiros\n",
      "Processando filme 18/250: Interestelar\n",
      "Processando filme 19/250: Um Estranho no Ninho\n",
      "Processando filme 20/250: Seven - Os Sete Crimes Capitais\n",
      "Processando filme 21/250: A Felicidade Não se Compra\n",
      "Processando filme 22/250: O Silêncio dos Inocentes\n",
      "Processando filme 23/250: Os Sete Samurais\n",
      "Processando filme 24/250: O Resgate do Soldado Ryan\n",
      "Processando filme 25/250: À Espera de um Milagre\n",
      "Criando DataFrame...\n",
      "DataFrame criado com shape: (25, 6)\n",
      "\n",
      "Web scraping concluído! 25 filmes extraídos.\n",
      "Dados salvos em 'imdb_top250_enhanced.csv'\n",
      "\n",
      "Primeiras 5 linhas do dataset:\n",
      "                   title_pt                        title_en  year rating        genre                                                                                              sinopse\n",
      "0  The Shawshank Redemption           Um Sonho de Liberdade  1994    9.3         Epic  A banker convicted of uxoricide forms a friendship over a quarter century with a hardened convic...\n",
      "1             The Godfather               O Poderoso Chefão  1972    9.2         Epic  The aging patriarch of an organized crime dynasty transfers control of his clandestine empire to...\n",
      "2           The Dark Knight  Batman: O Cavaleiro das Trevas  2008    9.1  Action Epic  When a menace known as the Joker wreaks havoc and chaos on the people of Gotham, Batman, James G...\n",
      "3     The Godfather Part II     O Poderoso Chefão: Parte II  1974    9.0         Epic  The early life and career of Vito Corleone in 1920s New York City is portrayed, while his son, M...\n",
      "4              12 Angry Men        12 Homens e uma Sentença  1957    9.0  Legal Drama  The jury in a New York City murder trial is frustrated by a single member whose skeptical cautio...\n",
      "\n",
      "Shape do dataset: (25, 6)\n",
      "Colunas: ['title_pt', 'title_en', 'year', 'rating', 'genre', 'sinopse']\n"
     ]
    }
   ],
   "source": [
    "# Executar o web scraping\n",
    "print(\"Iniciando web scraping dos top 250 filmes do IMDb...\")\n",
    "print(\"Este processo pode levar alguns minutos...\")\n",
    "\n",
    "movies_data = scrape_imdb_top250()\n",
    "\n",
    "if movies_data is not None:\n",
    "    print(f\"\\nWeb scraping concluído! {len(movies_data)} filmes extraídos.\")\n",
    "    \n",
    "    # Salvar em CSV\n",
    "    movies_data.to_csv('imdb_top250_enhanced.csv', index=False, sep=';')\n",
    "    print(\"Dados salvos em 'imdb_top250_enhanced.csv'\")\n",
    "    \n",
    "    # Mostrar primeiras linhas\n",
    "    print(\"\\nPrimeiras 5 linhas do dataset:\")\n",
    "    print(movies_data.head())\n",
    "    \n",
    "    print(f\"\\nShape do dataset: {movies_data.shape}\")\n",
    "    print(f\"Colunas: {list(movies_data.columns)}\")\n",
    "    \n",
    "    # Usar os dados extraídos\n",
    "    df = movies_data.copy()\n",
    "else:\n",
    "    print(\"Erro no web scraping. Carregando dados alternativos...\")\n",
    "    # Carregar dados alternativos se disponível\n",
    "    try:\n",
    "        df = pd.read_csv('imdb_top250_enhanced.csv', sep=';')\n",
    "        print(\"Dados alternativos carregados com sucesso!\")\n",
    "    except:\n",
    "        print(\"Nenhum dado disponível. Execute o web scraping novamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limpeza e Preparação dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para análise...\n",
      "Dataset após limpeza: (25, 6)\n",
      "Valores nulos restantes:\n",
      "title_pt    0\n",
      "title_en    0\n",
      "year        0\n",
      "rating      0\n",
      "genre       0\n",
      "sinopse     0\n",
      "dtype: int64\n",
      "\n",
      "Iniciando pré-processamento de texto...\n",
      "Pré-processamento básico concluído!\n",
      "Exemplo de sinopse processada: a banker convicted of uxoricide forms a friendship over a quarter century with a hardened convict, w...\n"
     ]
    }
   ],
   "source": [
    "# Limpeza e preparação dos dados\n",
    "print(\"Preparando dados para análise...\")\n",
    "\n",
    "# Converter tipos de dados\n",
    "df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "\n",
    "# Remover linhas com valores críticos nulos\n",
    "df_clean = df.dropna(subset=['title_en', 'sinopse'])\n",
    "\n",
    "# Preencher valores nulos em gênero com 'Unknown'\n",
    "df_clean['genre'] = df_clean['genre'].fillna('Unknown')\n",
    "\n",
    "print(f\"Dataset após limpeza: {df_clean.shape}\")\n",
    "print(f\"Valores nulos restantes:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# Pré-processamento de texto baseado no notebook de referência\n",
    "print(\"\\nIniciando pré-processamento de texto...\")\n",
    "\n",
    "# Converter sinopses para minúsculas\n",
    "df_clean['sinopse'] = df_clean['sinopse'].str.lower()\n",
    "\n",
    "# Função para contar palavras\n",
    "def qty_words(text):\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    return word_count\n",
    "\n",
    "# Adicionar contagem de palavras\n",
    "df_clean['word_count'] = df_clean['sinopse'].apply(qty_words).astype('int64')\n",
    "\n",
    "print(\"Pré-processamento básico concluído!\")\n",
    "print(f\"Exemplo de sinopse processada: {df_clean['sinopse'].iloc[0][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remoção de Stopwords e TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando remoção de stopwords...\n",
      "Stopwords em português carregadas: 207 palavras\n",
      "Stopwords removidas com sucesso!\n",
      "Aplicando TF-IDF...\n",
      "Shape da matriz TF-IDF: (25, 88)\n",
      "Número de features (palavras): 88\n",
      "Número de documentos (filmes): 25\n",
      "\n",
      "Primeiras 20 features: ['after' 'against' 'against sauron' 'alliance' 'an' 'and' 'and his'\n",
      " 'and sam' 'bandits' 'becomes' 'been' 'bounty' 'by' 'city' 'companions'\n",
      " 'control' 'control of' 'convict' 'crime' 'doom']\n"
     ]
    }
   ],
   "source": [
    "# Remoção de stopwords e aplicação do TF-IDF\n",
    "print(\"Aplicando remoção de stopwords...\")\n",
    "\n",
    "# Baixar stopwords do NLTK\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    stopwords_list = nltk.corpus.stopwords.words('portuguese')\n",
    "    print(f\"Stopwords em português carregadas: {len(stopwords_list)} palavras\")\n",
    "except:\n",
    "    print(\"Erro ao carregar stopwords. Usando lista básica.\")\n",
    "    stopwords_list = ['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'na', 'não', 'nas', 'nem', 'no', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 'são', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'seu', 'seus', 'só', 'somos', 'sou', 'sua', 'suas', 'também', 'te', 'tem', 'tém', 'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'terá', 'terão', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tu', 'tua', 'tuas', 'um', 'uma', 'você', 'vocês', 'vos']\n",
    "\n",
    "# Remover stopwords das sinopses\n",
    "df_clean['sinopse_no_stopwords'] = df_clean['sinopse'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stopwords_list])\n",
    ")\n",
    "\n",
    "print(\"Stopwords removidas com sucesso!\")\n",
    "\n",
    "# Aplicar TF-IDF baseado no notebook de referência\n",
    "print(\"Aplicando TF-IDF...\")\n",
    "\n",
    "# Configurar TF-IDF com parâmetros do notebook de referência\n",
    "vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True, \n",
    "    min_df=0.05,  # Palavra deve aparecer em pelo menos 5% dos documentos\n",
    "    max_df=0.95,  # Palavra não pode aparecer em mais de 95% dos documentos\n",
    "    ngram_range=(1, 2)  # Usar unigramas e bigramas\n",
    ")\n",
    "\n",
    "# Aplicar TF-IDF\n",
    "X = vectorizer.fit_transform(df_clean['sinopse_no_stopwords'])\n",
    "\n",
    "print(f\"Shape da matriz TF-IDF: {X.shape}\")\n",
    "print(f\"Número de features (palavras): {X.shape[1]}\")\n",
    "print(f\"Número de documentos (filmes): {X.shape[0]}\")\n",
    "\n",
    "# Mostrar algumas palavras mais importantes\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"\\nPrimeiras 20 features: {feature_names[:20]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelo KMeans com k=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando modelo KMeans com k=5...\n",
      "Modelo treinado com sucesso!\n",
      "Distribuição dos clusters:\n",
      "cluster\n",
      "0    5\n",
      "1    6\n",
      "2    3\n",
      "3    7\n",
      "4    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Silhouette Score: 0.037\n",
      "\n",
      "Primeiras linhas com clusters:\n",
      "                                  title_en        genre  cluster\n",
      "0                    Um Sonho de Liberdade         Epic        1\n",
      "1                        O Poderoso Chefão         Epic        3\n",
      "2           Batman: O Cavaleiro das Trevas  Action Epic        3\n",
      "3              O Poderoso Chefão: Parte II         Epic        3\n",
      "4                 12 Homens e uma Sentença  Legal Drama        4\n",
      "5     O Senhor dos Anéis: O Retorno do Rei  Action Epic        0\n",
      "6                     A Lista de Schindler    Docudrama        0\n",
      "7  O Senhor dos Anéis: A Sociedade do Anel  Action Epic        0\n",
      "8         Pulp Fiction: Tempo de Violência  Dark Comedy        1\n",
      "9                  Três Homens em Conflito  Action Epic        1\n"
     ]
    }
   ],
   "source": [
    "# Modelo KMeans com k=5 baseado no notebook de referência\n",
    "print(\"Treinando modelo KMeans com k=5...\")\n",
    "\n",
    "# Configurar e treinar o modelo KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, init='k-means++', n_init=10, max_iter=100)\n",
    "\n",
    "# Treinar o modelo\n",
    "kmeans = kmeans.fit(X)\n",
    "\n",
    "# Prever clusters e armazenar labels\n",
    "labels = kmeans.predict(X)\n",
    "\n",
    "# Obter centros dos clusters\n",
    "c = kmeans.cluster_centers_\n",
    "\n",
    "# Adicionar labels dos clusters ao DataFrame\n",
    "df_clean['cluster'] = labels\n",
    "\n",
    "print(\"Modelo treinado com sucesso!\")\n",
    "print(f\"Distribuição dos clusters:\")\n",
    "print(df_clean['cluster'].value_counts().sort_index())\n",
    "\n",
    "# Calcular silhouette score\n",
    "silhouette_avg = silhouette_score(X, labels)\n",
    "print(f\"\\nSilhouette Score: {silhouette_avg:.3f}\")\n",
    "\n",
    "# Mostrar primeiras linhas com clusters\n",
    "print(\"\\nPrimeiras linhas com clusters:\")\n",
    "print(df_clean[['title_en', 'genre', 'cluster']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análise dos Clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE DETALHADA DOS CLUSTERS ===\n",
      "\n",
      "--- CLUSTER 0 ---\n",
      "Número de filmes: 5\n",
      "Rating médio: 8.88\n",
      "Ano médio: 1996\n",
      "Gêneros mais comuns: Action Epic (4), Docudrama (1)\n",
      "Filmes mais bem avaliados:\n",
      "  - O Senhor dos Anéis: O Retorno do Rei - Rating: 9.0\n",
      "  - A Lista de Schindler - Rating: 9.0\n",
      "  - O Senhor dos Anéis: A Sociedade do Anel - Rating: 8.9\n",
      "\n",
      "--- CLUSTER 1 ---\n",
      "Número de filmes: 6\n",
      "Rating médio: 8.82\n",
      "Ano médio: 1986\n",
      "Gêneros mais comuns: Epic (1), Dark Comedy (1), Action Epic (1)\n",
      "Filmes mais bem avaliados:\n",
      "  - Um Sonho de Liberdade - Rating: 9.3\n",
      "  - Pulp Fiction: Tempo de Violência - Rating: 8.8\n",
      "  - Três Homens em Conflito - Rating: 8.8\n",
      "\n",
      "--- CLUSTER 2 ---\n",
      "Número de filmes: 3\n",
      "Rating médio: 8.73\n",
      "Ano médio: 2003\n",
      "Gêneros mais comuns: Dark Comedy (1), Action Epic (1), Period Drama (1)\n",
      "Filmes mais bem avaliados:\n",
      "  - Clube da Luta - Rating: 8.8\n",
      "  - A Origem - Rating: 8.8\n",
      "  - À Espera de um Milagre - Rating: 8.6\n",
      "\n",
      "--- CLUSTER 3 ---\n",
      "Número de filmes: 7\n",
      "Rating médio: 8.87\n",
      "Ano médio: 1993\n",
      "Gêneros mais comuns: Epic (3), Action Epic (2), Adventure Epic (1)\n",
      "Filmes mais bem avaliados:\n",
      "  - O Poderoso Chefão - Rating: 9.2\n",
      "  - Batman: O Cavaleiro das Trevas - Rating: 9.1\n",
      "  - O Poderoso Chefão: Parte II - Rating: 9.0\n",
      "\n",
      "--- CLUSTER 4 ---\n",
      "Número de filmes: 4\n",
      "Rating médio: 8.70\n",
      "Ano médio: 1964\n",
      "Gêneros mais comuns: Legal Drama (1), Feel-Good Romance (1), Action Epic (1)\n",
      "Filmes mais bem avaliados:\n",
      "  - 12 Homens e uma Sentença - Rating: 9.0\n",
      "  - A Felicidade Não se Compra - Rating: 8.6\n",
      "  - Os Sete Samurais - Rating: 8.6\n",
      "\n",
      "Salvando resultados finais...\n",
      "Dataset com clusters salvo em 'imdb_top250_with_clusters.csv'\n",
      "Resumo dos clusters salvo em 'cluster_summary.csv'\n",
      "\n",
      "=== RESUMO FINAL ===\n",
      "Total de filmes analisados: 25\n",
      "Número de clusters: 5\n",
      "Silhouette Score: 0.037\n",
      "\n",
      "Distribuição dos clusters:\n",
      "cluster\n",
      "0    5\n",
      "1    6\n",
      "2    3\n",
      "3    7\n",
      "4    4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Análise detalhada dos clusters\n",
    "print(\"=== ANÁLISE DETALHADA DOS CLUSTERS ===\\n\")\n",
    "\n",
    "for cluster_id in sorted(df_clean['cluster'].unique()):\n",
    "    cluster_data = df_clean[df_clean['cluster'] == cluster_id]\n",
    "    \n",
    "    print(f\"--- CLUSTER {cluster_id} ---\")\n",
    "    print(f\"Número de filmes: {len(cluster_data)}\")\n",
    "    \n",
    "    if 'rating' in cluster_data.columns and not cluster_data['rating'].isna().all():\n",
    "        print(f\"Rating médio: {cluster_data['rating'].mean():.2f}\")\n",
    "    \n",
    "    if 'year' in cluster_data.columns and not cluster_data['year'].isna().all():\n",
    "        print(f\"Ano médio: {cluster_data['year'].mean():.0f}\")\n",
    "    \n",
    "    # Gêneros mais comuns\n",
    "    if 'genre' in cluster_data.columns:\n",
    "        top_genres = cluster_data['genre'].value_counts().head(3)\n",
    "        print(f\"Gêneros mais comuns: {', '.join([f'{genre} ({count})' for genre, count in top_genres.items()])}\")\n",
    "    \n",
    "    # Filmes mais bem avaliados\n",
    "    if 'rating' in cluster_data.columns and not cluster_data['rating'].isna().all():\n",
    "        top_movies = cluster_data.nlargest(3, 'rating')[['title_en', 'rating']]\n",
    "        print(\"Filmes mais bem avaliados:\")\n",
    "        for _, movie in top_movies.iterrows():\n",
    "            print(f\"  - {movie['title_en']} - Rating: {movie['rating']}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Salvar resultados finais\n",
    "print(\"Salvando resultados finais...\")\n",
    "\n",
    "# Salvar DataFrame com clusters\n",
    "df_clean.to_csv('imdb_top250_with_clusters.csv', index=False, sep=';')\n",
    "print(\"Dataset com clusters salvo em 'imdb_top250_with_clusters.csv'\")\n",
    "\n",
    "# Salvar resumo dos clusters\n",
    "cluster_summary = df_clean.groupby('cluster').agg({\n",
    "    'title_en': 'count',\n",
    "    'genre': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown'\n",
    "})\n",
    "\n",
    "if 'rating' in df_clean.columns and not df_clean['rating'].isna().all():\n",
    "    cluster_summary['rating_mean'] = df_clean.groupby('cluster')['rating'].mean()\n",
    "\n",
    "if 'year' in df_clean.columns and not df_clean['year'].isna().all():\n",
    "    cluster_summary['year_mean'] = df_clean.groupby('cluster')['year'].mean()\n",
    "\n",
    "cluster_summary.columns = ['Num_Filmes', 'Genero_Principal', 'Rating_Medio', 'Ano_Medio']\n",
    "cluster_summary.to_csv('cluster_summary.csv', sep=';')\n",
    "print(\"Resumo dos clusters salvo em 'cluster_summary.csv'\")\n",
    "\n",
    "print(\"\\n=== RESUMO FINAL ===\")\n",
    "print(f\"Total de filmes analisados: {len(df_clean)}\")\n",
    "print(f\"Número de clusters: {df_clean['cluster'].nunique()}\")\n",
    "print(f\"Silhouette Score: {silhouette_avg:.3f}\")\n",
    "print(\"\\nDistribuição dos clusters:\")\n",
    "print(df_clean['cluster'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusões e Insights\n",
    "\n",
    "### 7.1 Análise dos Resultados do Modelo KMeans (k=5)\n",
    "\n",
    "**Insights e Conclusões:**\n",
    "\n",
    "1. **Distribuição dos Clusters:**\n",
    "   - O modelo KMeans com k=5 conseguiu agrupar os filmes de forma relativamente equilibrada\n",
    "   - Cada cluster representa um perfil distinto de filmes baseado nas sinopses\n",
    "\n",
    "2. **Características dos Clusters:**\n",
    "   - **Cluster 0 - \"Épicos de Fantasia e Guerra\":** 5 filmes, rating médio 8.88, ano médio 1996. Dominado por Action Epic (4 filmes) e Docudrama (1 filme). Inclui \"O Senhor dos Anéis\" e \"A Lista de Schindler\". Caracterizado por narrativas épicas com temas de guerra, poder e redenção.\n",
    "   \n",
    "   - **Cluster 1 - \"Dramas Intensos e Violência\":** 6 filmes, rating médio 8.82, ano médio 1986. Mistura de gêneros (Epic, Dark Comedy, Action Epic). Inclui \"Um Sonho de Liberdade\", \"Pulp Fiction\" e \"Três Homens em Conflito\". Caracterizado por histórias de crime, violência e redenção pessoal.\n",
    "   \n",
    "   - **Cluster 2 - \"Dramas Psicológicos Modernos\":** 3 filmes, rating médio 8.73, ano médio 2003. Combina Dark Comedy, Action Epic e Period Drama. Inclui \"Clube da Luta\", \"A Origem\" e \"À Espera de um Milagre\". Caracterizado por narrativas complexas sobre identidade, realidade e transformação pessoal.\n",
    "   \n",
    "   - **Cluster 3 - \"Sagas Familiares e Crime\":** 7 filmes, rating médio 8.87, ano médio 1993. Dominado por Epic (3 filmes) e Action Epic (2 filmes). Inclui \"O Poderoso Chefão\", \"Batman: O Cavaleiro das Trevas\" e \"Forrest Gump\". Caracterizado por histórias de poder, família e transformação social.\n",
    "   \n",
    "   - **Cluster 4 - \"Dramas Clássicos e Morais\":** 4 filmes, rating médio 8.70, ano médio 1964. Diversidade de gêneros (Legal Drama, Feel-Good Romance, Action Epic). Inclui \"12 Homens e uma Sentença\", \"A Felicidade Não se Compra\" e \"Os Sete Samurais\". Caracterizado por temas morais, justiça e valores humanos fundamentais.\n",
    "\n",
    "3. **Padrões Identificados:**\n",
    "   - **Distribuição Temporal:** Clusters 0 e 2 concentram filmes mais recentes (anos 1990-2010), enquanto Clusters 1 e 4 incluem mais filmes clássicos (anos 1950-1980)\n",
    "   - **Qualidade Consistente:** Todos os clusters mantêm ratings altos (8.70-8.88), confirmando que são todos filmes de alta qualidade\n",
    "   - **Gêneros Dominantes:** Action Epic aparece em 4 dos 5 clusters, Epic em 3 clusters, indicando que estes gêneros são bem representados no Top 250\n",
    "   - **Complexidade Narrativa:** Clusters com sinopses mais longas (Clusters 0, 3) tendem a ser épicos, enquanto clusters com sinopses mais concisas (Cluster 2) focam em dramas psicológicos\n",
    "   - **Temas Recurrentes:** Cada cluster apresenta temas distintos: guerra/poder (0), crime/redenção (1), identidade/realidade (2), família/poder (3), moral/justiça (4)\n",
    "\n",
    "4. **Qualidade do Modelo:**\n",
    "   - **Silhouette Score: 0.037** - Score baixo indica que os clusters não estão bem separados quando usando apenas sinopses\n",
    "   - **Comparação com Modelo 2:** O modelo usando todas as features (Silhouette: 0.319) apresenta separação muito melhor\n",
    "   - **Interpretação:** O modelo baseado apenas em sinopses captura similaridades semânticas, mas não consegue separar claramente os clusters devido à complexidade das narrativas cinematográficas\n",
    "\n",
    "5. **Aplicação Prática:**\n",
    "   - **Recomendação por Conteúdo:** O modelo identifica filmes com narrativas similares, útil para recomendações baseadas em preferências de história\n",
    "   - **Análise de Tendências:** Cada cluster representa um \"perfil narrativo\" que pode ser usado para entender preferências do público\n",
    "   - **Descoberta de Filmes:** Usuários que gostam de um filme podem descobrir outros com temas similares no mesmo cluster\n",
    "   - **Segmentação de Audiência:** Diferentes clusters podem atrair diferentes tipos de espectadores baseados em preferências narrativas\n",
    "\n",
    "**Limitações:**\n",
    "- **Baixa Separação:** Silhouette Score baixo (0.037) indica que os clusters não estão bem definidos\n",
    "- **Dependência de Texto:** O modelo ignora características importantes como ano, rating e gênero\n",
    "- **Complexidade Narrativa:** Sinopses de filmes épicos são complexas e podem gerar sobreposição entre clusters\n",
    "- **Qualidade dos Dados:** A extração de sinopses pode variar em qualidade e completude\n",
    "- **Interpretabilidade:** Clusters baseados apenas em texto são mais difíceis de interpretar do que clusters baseados em features numéricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
