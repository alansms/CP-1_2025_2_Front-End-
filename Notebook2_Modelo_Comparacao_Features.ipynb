{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Comparação de Modelos KMeans - Sinopse vs Todas as Features\n",
    "\n",
    "**Objetivo:** Comparar o desempenho do modelo KMeans utilizando apenas sinopses vetorizadas versus utilizando todas as features disponíveis\n",
    "\n",
    "**Desenvolvido por:** [Nome dos integrantes do grupo]\n",
    "\n",
    "**Data:** 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação das Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n",
      "Python version: 2.3.0\n",
      "NumPy version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# Instalação das bibliotecas necessárias (execute apenas se necessário)\n",
    "# !pip install requests beautifulsoup4 pandas numpy matplotlib seaborn plotly wordcloud scikit-learn nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "\n",
    "# Configurações\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "print(f\"Python version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados do Notebook 1...\n",
      "Dataset com clusters carregado com sucesso!\n",
      "Shape: (25, 9)\n",
      "Colunas: ['title_pt', 'title_en', 'year', 'rating', 'genre', 'sinopse', 'word_count', 'sinopse_no_stopwords', 'cluster']\n",
      "\n",
      "Primeiras 5 linhas:\n",
      "                   title_pt                        title_en  year  rating        genre                                                                                              sinopse  word_count                                                                                 sinopse_no_stopwords  cluster\n",
      "0  The Shawshank Redemption           Um Sonho de Liberdade  1994     9.3         Epic  a banker convicted of uxoricide forms a friendship over a quarter century with a hardened convic...          28  banker convicted of uxoricide forms friendship over quarter century with hardened convict, while...        1\n",
      "1             The Godfather               O Poderoso Chefão  1972     9.2         Epic  the aging patriarch of an organized crime dynasty transfers control of his clandestine empire to...          18  the aging patriarch of an organized crime dynasty transfers control of his clandestine empire to...        3\n",
      "2           The Dark Knight  Batman: O Cavaleiro das Trevas  2008     9.1  Action Epic  when a menace known as the joker wreaks havoc and chaos on the people of gotham, batman, james g...          32  when menace known the joker wreaks havoc and chaos on the people of gotham, batman, james gordon...        3\n",
      "3     The Godfather Part II     O Poderoso Chefão: Parte II  1974     9.0         Epic  the early life and career of vito corleone in 1920s new york city is portrayed, while his son, m...          29  the early life and career of vito corleone in 1920s new york city is portrayed, while his son, m...        3\n",
      "4              12 Angry Men        12 Homens e uma Sentença  1957     9.0  Legal Drama  the jury in a new york city murder trial is frustrated by a single member whose skeptical cautio...          32  the jury in new york city murder trial is frustrated by single member whose skeptical caution fo...        4\n",
      "\n",
      "Shape do dataset: (25, 9)\n",
      "Colunas: ['title_pt', 'title_en', 'year', 'rating', 'genre', 'sinopse', 'word_count', 'sinopse_no_stopwords', 'cluster']\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados do Notebook 1\n",
    "print(\"Carregando dados do Notebook 1...\")\n",
    "\n",
    "try:\n",
    "    # Tentar carregar o dataset com clusters do Notebook 1\n",
    "    df = pd.read_csv('imdb_top250_with_clusters.csv', sep=';')\n",
    "    print(\"Dataset com clusters carregado com sucesso!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Colunas: {list(df.columns)}\")\n",
    "    \n",
    "    # Mostrar primeiras linhas\n",
    "    print(\"\\nPrimeiras 5 linhas:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo 'imdb_top250_with_clusters.csv' não encontrado.\")\n",
    "    try:\n",
    "        # Tentar carregar o dataset original\n",
    "        df = pd.read_csv('imdb_top250_enhanced.csv', sep=';')\n",
    "        print(\"Dataset original carregado com sucesso!\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(f\"Colunas: {list(df.columns)}\")\n",
    "        \n",
    "        # Mostrar primeiras linhas\n",
    "        print(\"\\nPrimeiras 5 linhas:\")\n",
    "        print(df.head())\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Erro ao carregar dataset. Verifique se os arquivos existem.\")\n",
    "        # Criar dataset de exemplo para demonstração\n",
    "        df = pd.DataFrame({\n",
    "            'title_pt': ['Filme 1', 'Filme 2', 'Filme 3'],\n",
    "            'title_en': ['Movie 1', 'Movie 2', 'Movie 3'],\n",
    "            'year': [2020, 2021, 2022],\n",
    "            'rating': [8.5, 7.8, 9.2],\n",
    "            'genre': ['Action', 'Drama', 'Comedy'],\n",
    "            'sinopse': ['Ação emocionante', 'Drama tocante', 'Comédia divertida']\n",
    "        })\n",
    "        print(\"Dataset de exemplo criado para demonstração.\")\n",
    "\n",
    "print(f\"\\nShape do dataset: {df.shape}\")\n",
    "print(f\"Colunas: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparação dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para comparação dos modelos...\n",
      "Dataset após limpeza: (25, 9)\n",
      "Valores nulos restantes:\n",
      "title_pt                0\n",
      "title_en                0\n",
      "year                    0\n",
      "rating                  0\n",
      "genre                   0\n",
      "sinopse                 0\n",
      "word_count              0\n",
      "sinopse_no_stopwords    0\n",
      "cluster                 0\n",
      "dtype: int64\n",
      "\n",
      "Estatísticas básicas:\n",
      "              year     rating  word_count    cluster\n",
      "count    25.000000  25.000000   25.000000  25.000000\n",
      "mean   1988.320000   8.816000   27.240000   1.960000\n",
      "std      18.091711   0.199332    5.456495   1.428286\n",
      "min    1946.000000   8.600000   16.000000   0.000000\n",
      "25%    1975.000000   8.700000   24.000000   1.000000\n",
      "50%    1994.000000   8.800000   28.000000   2.000000\n",
      "75%    1999.000000   9.000000   31.000000   3.000000\n",
      "max    2014.000000   9.300000   40.000000   4.000000\n"
     ]
    }
   ],
   "source": [
    "# Preparação dos dados para comparação\n",
    "print(\"Preparando dados para comparação dos modelos...\")\n",
    "\n",
    "# Limpeza dos dados\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Converter tipos de dados\n",
    "df_clean['year'] = pd.to_numeric(df_clean['year'], errors='coerce')\n",
    "df_clean['rating'] = pd.to_numeric(df_clean['rating'], errors='coerce')\n",
    "\n",
    "# Remover linhas com valores críticos nulos\n",
    "df_clean = df_clean.dropna(subset=['title_en', 'sinopse'])\n",
    "\n",
    "# Preencher valores nulos\n",
    "df_clean['genre'] = df_clean['genre'].fillna('Unknown')\n",
    "df_clean['year'] = df_clean['year'].fillna(df_clean['year'].median())\n",
    "df_clean['rating'] = df_clean['rating'].fillna(df_clean['rating'].median())\n",
    "\n",
    "# Pré-processamento de texto\n",
    "df_clean['sinopse'] = df_clean['sinopse'].str.lower()\n",
    "\n",
    "# Função para contar palavras\n",
    "def qty_words(text):\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    return word_count\n",
    "\n",
    "# Adicionar contagem de palavras\n",
    "df_clean['word_count'] = df_clean['sinopse'].apply(qty_words).astype('int64')\n",
    "\n",
    "print(f\"Dataset após limpeza: {df_clean.shape}\")\n",
    "print(f\"Valores nulos restantes:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# Mostrar estatísticas básicas\n",
    "print(\"\\nEstatísticas básicas:\")\n",
    "print(df_clean.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelo 1: KMeans com Apenas Sinopses (TF-IDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODELO 1: KMEANS COM APENAS SINOPSES ===\n",
      "\n",
      "Stopwords em português carregadas: 207 palavras\n",
      "Stopwords removidas com sucesso!\n",
      "Aplicando TF-IDF...\n",
      "Shape da matriz TF-IDF: (25, 88)\n",
      "Número de features (palavras): 88\n",
      "Número de documentos (filmes): 25\n",
      "\n",
      "Treinando modelo KMeans com k=5...\n",
      "\n",
      "Métricas do Modelo 1 (TF-IDF):\n",
      "Silhouette Score: 0.037\n",
      "Calinski-Harabasz Score: 1.612\n",
      "Davies-Bouldin Score: 2.450\n",
      "\n",
      "Distribuição dos clusters (Modelo 1):\n",
      "cluster_tfidf\n",
      "0    5\n",
      "1    6\n",
      "2    3\n",
      "3    7\n",
      "4    4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Modelo 1: KMeans usando apenas sinopses vetorizadas\n",
    "print(\"=== MODELO 1: KMEANS COM APENAS SINOPSES ===\\n\")\n",
    "\n",
    "# Remoção de stopwords\n",
    "import nltk\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    stopwords_list = nltk.corpus.stopwords.words('portuguese')\n",
    "    print(f\"Stopwords em português carregadas: {len(stopwords_list)} palavras\")\n",
    "except:\n",
    "    print(\"Erro ao carregar stopwords. Usando lista básica.\")\n",
    "    stopwords_list = ['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'na', 'não', 'nas', 'nem', 'no', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 'são', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'seu', 'seus', 'só', 'somos', 'sou', 'sua', 'suas', 'também', 'te', 'tem', 'tém', 'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'terá', 'terão', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tu', 'tua', 'tuas', 'um', 'uma', 'você', 'vocês', 'vos']\n",
    "\n",
    "# Remover stopwords das sinopses\n",
    "df_clean['sinopse_no_stopwords'] = df_clean['sinopse'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stopwords_list])\n",
    ")\n",
    "\n",
    "print(\"Stopwords removidas com sucesso!\")\n",
    "\n",
    "# Aplicar TF-IDF\n",
    "print(\"Aplicando TF-IDF...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True, \n",
    "    min_df=0.05,  # Palavra deve aparecer em pelo menos 5% dos documentos\n",
    "    max_df=0.95,  # Palavra não pode aparecer em mais de 95% dos documentos\n",
    "    ngram_range=(1, 2)  # Usar unigramas e bigramas\n",
    ")\n",
    "\n",
    "# Aplicar TF-IDF\n",
    "X_tfidf = vectorizer.fit_transform(df_clean['sinopse_no_stopwords'])\n",
    "\n",
    "print(f\"Shape da matriz TF-IDF: {X_tfidf.shape}\")\n",
    "print(f\"Número de features (palavras): {X_tfidf.shape[1]}\")\n",
    "print(f\"Número de documentos (filmes): {X_tfidf.shape[0]}\")\n",
    "\n",
    "# Treinar modelo KMeans com k=5\n",
    "print(\"\\nTreinando modelo KMeans com k=5...\")\n",
    "kmeans_tfidf = KMeans(n_clusters=5, random_state=42, init='k-means++', n_init=10, max_iter=100)\n",
    "kmeans_tfidf = kmeans_tfidf.fit(X_tfidf)\n",
    "\n",
    "# Prever clusters\n",
    "labels_tfidf = kmeans_tfidf.predict(X_tfidf)\n",
    "\n",
    "# Adicionar labels dos clusters ao DataFrame\n",
    "df_clean['cluster_tfidf'] = labels_tfidf\n",
    "\n",
    "# Calcular métricas de avaliação\n",
    "silhouette_tfidf = silhouette_score(X_tfidf, labels_tfidf)\n",
    "calinski_tfidf = calinski_harabasz_score(X_tfidf.toarray(), labels_tfidf)\n",
    "davies_tfidf = davies_bouldin_score(X_tfidf.toarray(), labels_tfidf)\n",
    "\n",
    "print(f\"\\nMétricas do Modelo 1 (TF-IDF):\")\n",
    "print(f\"Silhouette Score: {silhouette_tfidf:.3f}\")\n",
    "print(f\"Calinski-Harabasz Score: {calinski_tfidf:.3f}\")\n",
    "print(f\"Davies-Bouldin Score: {davies_tfidf:.3f}\")\n",
    "\n",
    "print(f\"\\nDistribuição dos clusters (Modelo 1):\")\n",
    "print(df_clean['cluster_tfidf'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelo 2: KMeans com Todas as Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODELO 2: KMEANS COM TODAS AS FEATURES ===\n",
      "\n",
      "Preparando features numéricas...\n",
      "Features numéricas normalizadas: (25, 3)\n",
      "Preparando features categóricas...\n",
      "Features categóricas codificadas: (25, 1)\n",
      "Gêneros únicos: 11\n",
      "Combinando todas as features...\n",
      "Matriz final com todas as features: (25, 4)\n",
      "\n",
      "Treinando modelo KMeans com k=5...\n",
      "\n",
      "Métricas do Modelo 2 (Todas as Features):\n",
      "Silhouette Score: 0.319\n",
      "Calinski-Harabasz Score: 24.536\n",
      "Davies-Bouldin Score: 0.934\n",
      "\n",
      "Distribuição dos clusters (Modelo 2):\n",
      "cluster_all\n",
      "0    7\n",
      "1    6\n",
      "2    6\n",
      "3    3\n",
      "4    3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Modelo 2: KMeans usando todas as features disponíveis\n",
    "print(\"=== MODELO 2: KMEANS COM TODAS AS FEATURES ===\\n\")\n",
    "\n",
    "# Preparar features numéricas\n",
    "print(\"Preparando features numéricas...\")\n",
    "\n",
    "# Features numéricas\n",
    "numeric_features = ['year', 'rating', 'word_count']\n",
    "X_numeric = df_clean[numeric_features].values\n",
    "\n",
    "# Normalizar features numéricas\n",
    "scaler = StandardScaler()\n",
    "X_numeric_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "print(f\"Features numéricas normalizadas: {X_numeric_scaled.shape}\")\n",
    "\n",
    "# Features categóricas (gênero)\n",
    "print(\"Preparando features categóricas...\")\n",
    "le_genre = LabelEncoder()\n",
    "genre_encoded = le_genre.fit_transform(df_clean['genre'])\n",
    "X_genre = genre_encoded.reshape(-1, 1)\n",
    "\n",
    "print(f\"Features categóricas codificadas: {X_genre.shape}\")\n",
    "print(f\"Gêneros únicos: {len(le_genre.classes_)}\")\n",
    "\n",
    "# Combinar todas as features\n",
    "print(\"Combinando todas as features...\")\n",
    "X_all_features = np.hstack([X_numeric_scaled, X_genre])\n",
    "\n",
    "print(f\"Matriz final com todas as features: {X_all_features.shape}\")\n",
    "\n",
    "# Treinar modelo KMeans com k=5\n",
    "print(\"\\nTreinando modelo KMeans com k=5...\")\n",
    "kmeans_all = KMeans(n_clusters=5, random_state=42, init='k-means++', n_init=10, max_iter=100)\n",
    "kmeans_all = kmeans_all.fit(X_all_features)\n",
    "\n",
    "# Prever clusters\n",
    "labels_all = kmeans_all.predict(X_all_features)\n",
    "\n",
    "# Adicionar labels dos clusters ao DataFrame\n",
    "df_clean['cluster_all'] = labels_all\n",
    "\n",
    "# Calcular métricas de avaliação\n",
    "silhouette_all = silhouette_score(X_all_features, labels_all)\n",
    "calinski_all = calinski_harabasz_score(X_all_features, labels_all)\n",
    "davies_all = davies_bouldin_score(X_all_features, labels_all)\n",
    "\n",
    "print(f\"\\nMétricas do Modelo 2 (Todas as Features):\")\n",
    "print(f\"Silhouette Score: {silhouette_all:.3f}\")\n",
    "print(f\"Calinski-Harabasz Score: {calinski_all:.3f}\")\n",
    "print(f\"Davies-Bouldin Score: {davies_all:.3f}\")\n",
    "\n",
    "print(f\"\\nDistribuição dos clusters (Modelo 2):\")\n",
    "print(df_clean['cluster_all'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparação dos Modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARAÇÃO DOS MODELOS ===\n",
      "\n",
      "Métricas de Comparação:\n",
      "                      Modelo  Silhouette Score  Calinski-Harabasz Score  Davies-Bouldin Score\n",
      "0          Modelo 1 (TF-IDF)             0.037                    1.612                 2.450\n",
      "1  Modelo 2 (Todas Features)             0.319                   24.536                 0.934\n",
      "\n",
      "=== ANÁLISE DOS RESULTADOS ===\n",
      "Melhor Silhouette Score: Modelo 2 (Todas Features) (diferença: 0.282)\n",
      "Melhor Calinski-Harabasz Score: Modelo 2 (Todas Features) (diferença: 22.924)\n",
      "Melhor Davies-Bouldin Score: Modelo 2 (Todas Features) (diferença: 1.516)\n",
      "\n",
      "Vitórias por modelo:\n",
      "Modelo 1 (TF-IDF): 0/3 métricas\n",
      "Modelo 2 (Todas Features): 3/3 métricas\n",
      "\n",
      "=== MELHOR MODELO: Modelo 2 (Todas Features) ===\n",
      "Justificativa: Melhor performance em mais métricas\n",
      "\n",
      "Resultados da comparação salvos em 'model_comparison_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "# Comparação detalhada dos dois modelos\n",
    "print(\"=== COMPARAÇÃO DOS MODELOS ===\\n\")\n",
    "\n",
    "# Criar DataFrame com métricas\n",
    "comparison_data = {\n",
    "    'Modelo': ['Modelo 1 (TF-IDF)', 'Modelo 2 (Todas Features)'],\n",
    "    'Silhouette Score': [silhouette_tfidf, silhouette_all],\n",
    "    'Calinski-Harabasz Score': [calinski_tfidf, calinski_all],\n",
    "    'Davies-Bouldin Score': [davies_tfidf, davies_all]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Métricas de Comparação:\")\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# Determinar o melhor modelo\n",
    "print(\"\\n=== ANÁLISE DOS RESULTADOS ===\")\n",
    "\n",
    "# Silhouette Score (maior é melhor)\n",
    "if silhouette_tfidf > silhouette_all:\n",
    "    best_silhouette = \"Modelo 1 (TF-IDF)\"\n",
    "    silhouette_diff = silhouette_tfidf - silhouette_all\n",
    "else:\n",
    "    best_silhouette = \"Modelo 2 (Todas Features)\"\n",
    "    silhouette_diff = silhouette_all - silhouette_tfidf\n",
    "\n",
    "# Calinski-Harabasz Score (maior é melhor)\n",
    "if calinski_tfidf > calinski_all:\n",
    "    best_calinski = \"Modelo 1 (TF-IDF)\"\n",
    "    calinski_diff = calinski_tfidf - calinski_all\n",
    "else:\n",
    "    best_calinski = \"Modelo 2 (Todas Features)\"\n",
    "    calinski_diff = calinski_all - calinski_tfidf\n",
    "\n",
    "# Davies-Bouldin Score (menor é melhor)\n",
    "if davies_tfidf < davies_all:\n",
    "    best_davies = \"Modelo 1 (TF-IDF)\"\n",
    "    davies_diff = davies_all - davies_tfidf\n",
    "else:\n",
    "    best_davies = \"Modelo 2 (Todas Features)\"\n",
    "    davies_diff = davies_tfidf - davies_all\n",
    "\n",
    "print(f\"Melhor Silhouette Score: {best_silhouette} (diferença: {silhouette_diff:.3f})\")\n",
    "print(f\"Melhor Calinski-Harabasz Score: {best_calinski} (diferença: {calinski_diff:.3f})\")\n",
    "print(f\"Melhor Davies-Bouldin Score: {best_davies} (diferença: {davies_diff:.3f})\")\n",
    "\n",
    "# Contar vitórias\n",
    "model1_wins = 0\n",
    "model2_wins = 0\n",
    "\n",
    "if best_silhouette == \"Modelo 1 (TF-IDF)\":\n",
    "    model1_wins += 1\n",
    "else:\n",
    "    model2_wins += 1\n",
    "\n",
    "if best_calinski == \"Modelo 1 (TF-IDF)\":\n",
    "    model1_wins += 1\n",
    "else:\n",
    "    model2_wins += 1\n",
    "\n",
    "if best_davies == \"Modelo 1 (TF-IDF)\":\n",
    "    model1_wins += 1\n",
    "else:\n",
    "    model2_wins += 1\n",
    "\n",
    "print(f\"\\nVitórias por modelo:\")\n",
    "print(f\"Modelo 1 (TF-IDF): {model1_wins}/3 métricas\")\n",
    "print(f\"Modelo 2 (Todas Features): {model2_wins}/3 métricas\")\n",
    "\n",
    "# Determinar o melhor modelo geral\n",
    "if model1_wins > model2_wins:\n",
    "    best_model = \"Modelo 1 (TF-IDF)\"\n",
    "    best_reason = \"Melhor performance em mais métricas\"\n",
    "elif model2_wins > model1_wins:\n",
    "    best_model = \"Modelo 2 (Todas Features)\"\n",
    "    best_reason = \"Melhor performance em mais métricas\"\n",
    "else:\n",
    "    best_model = \"Empate\"\n",
    "    best_reason = \"Performance similar em todas as métricas\"\n",
    "\n",
    "print(f\"\\n=== MELHOR MODELO: {best_model} ===\")\n",
    "print(f\"Justificativa: {best_reason}\")\n",
    "\n",
    "# Salvar resultados da comparação\n",
    "comparison_df.to_csv('model_comparison_summary.csv', index=False, sep=';')\n",
    "print(\"\\nResultados da comparação salvos em 'model_comparison_summary.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusões e Insights\n",
    "\n",
    "### 7.1 Análise Comparativa dos Modelos\n",
    "\n",
    "**Insights e Conclusões:**\n",
    "\n",
    "1. **Modelo 1 (TF-IDF apenas):**\n",
    "   - **Vantagens:** Foca no conteúdo semântico das sinopses, captura nuances de linguagem\n",
    "   - **Desvantagens:** Ignora características numéricas importantes como ano e rating\n",
    "   - **Aplicação:** Ideal para recomendações baseadas em conteúdo textual\n",
    "\n",
    "2. **Modelo 2 (Todas as Features):**\n",
    "   - **Vantagens:** Considera múltiplas dimensões (ano, rating, gênero, sinopse)\n",
    "   - **Desvantagens:** Pode ser influenciado por features com diferentes escalas\n",
    "   - **Aplicação:** Ideal para análises mais abrangentes e segmentação de mercado\n",
    "\n",
    "3. **Métricas de Avaliação:**\n",
    "   - **Silhouette Score:** Mede a qualidade da separação dos clusters\n",
    "   - **Calinski-Harabasz Score:** Avalia a compactação e separação dos clusters\n",
    "   - **Davies-Bouldin Score:** Mede a qualidade da clusterização (menor é melhor)\n",
    "\n",
    "4. **Escolha do Melhor Modelo:**\n",
    "   - Baseada na performance em múltiplas métricas\n",
    "   - Considera o contexto de aplicação\n",
    "   - Avalia a interpretabilidade dos resultados\n",
    "\n",
    "### 7.2 Recomendações\n",
    "\n",
    "**Para Recomendação de Filmes:**\n",
    "- Use o **Modelo 1** se o foco for similaridade de conteúdo\n",
    "- Use o **Modelo 2** se quiser considerar preferências demográficas\n",
    "\n",
    "**Para Análise de Mercado:**\n",
    "- Use o **Modelo 2** para segmentação mais abrangente\n",
    "- Use o **Modelo 1** para análise de tendências de conteúdo\n",
    "\n",
    "**Para Pesquisa Acadêmica:**\n",
    "- Use ambos os modelos para comparação\n",
    "- Documente as diferenças e aplicações específicas\n",
    "\n",
    "### 7.3 Limitações e Melhorias Futuras\n",
    "\n",
    "**Limitações:**\n",
    "- Dependência da qualidade dos dados extraídos\n",
    "- Possível overfitting com poucos dados\n",
    "- Interpretabilidade limitada dos clusters\n",
    "\n",
    "**Melhorias Futuras:**\n",
    "- Incorporar mais features (diretor, atores, orçamento)\n",
    "- Usar técnicas de redução de dimensionalidade (PCA, t-SNE)\n",
    "- Implementar validação cruzada\n",
    "- Testar diferentes algoritmos de clusterização\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
